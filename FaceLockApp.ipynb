{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition â€“ Unlock Your Computer With Your Face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-37-154175e9f57a>:16: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it returns the input image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "# Collect 100 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = './faces/user/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path = './faces/user/'\n",
    "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data, Labels = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
    "    Labels.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels = np.asarray(Labels, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "vimal_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "vimal_model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
    "print(\"Model trained sucessefully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    " os.environ[\"SenderMail\"] = \"pratikk2630@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Mail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "import os\n",
    "import getpass\n",
    "import imghdr\n",
    "from email.message import EmailMessage\n",
    "\n",
    "def send_email():\n",
    "    \n",
    "    message = EmailMessage()\n",
    "    \n",
    "    \n",
    "    \n",
    "    SenderMail = os.environ.get(\"SenderMail\")\n",
    "    #SenderPass = os.environ.get(\"SenderPass\")\n",
    "    #Recvmail = os.environ.get(\"Recvmail\")\n",
    "    print(SenderMail)\n",
    "    #print(SenderPass)\n",
    "    #print(Recvmail)\n",
    "    \n",
    "    #SenderMail = \"@gmail.com\"\n",
    "    #SenderMail = str(input(\"Enter sender mail:\"))\n",
    "    SenderPass = str(getpass.getpass(\"Enter sender pass:\"))\n",
    "    #RecvMail = str(input(\"Enter receiver mail\"))\n",
    "    Recvmail = os.environ.get(\"SenderMail\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Sending mail....\")\n",
    "    \n",
    "    message['subject'] = \"This is text code by pratik\"\n",
    "    message['from'] = SenderMail\n",
    "    message['to'] = Recvmail\n",
    "    message.set_content(\"Welcome to Face recognition app\" )#it will only display if html content is not visible\n",
    "    html_message = open(\"demo.html\").read()\n",
    "    message.add_alternative(html_message , subtype = \"html\")\n",
    "    \n",
    "    with open(\"./image/Crop.jpg\" , \"rb\") as attach_file:\n",
    "        image_name = attach_file.name\n",
    "        image_type = imghdr.what(attach_file.name)\n",
    "        image_data = attach_file.read()\n",
    "        \n",
    "    message.add_attachment(image_data , maintype = \"image\",\n",
    "                          subtype = image_type , filename = \"FaceLock.png\"\n",
    "                          )\n",
    "    \n",
    "    with smtplib.SMTP_SSL(\"smtp.gmail.com\",465) as smtp:#to connect with gmail server\n",
    "        smtp.login(SenderMail,SenderPass)\n",
    "        smtp.send_message(message)\n",
    "        \n",
    "    print(\"Mail Sent sucessfully\")\n",
    "    \n",
    "#send_email()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send Whats App Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywhatkit              #pywhatkit library is used for whatsapp operation using python\n",
    "from datetime import datetime #datetime module to get current time\n",
    "\n",
    "def wpmsg():\n",
    "    now = datetime.now()           # Get current time\n",
    "    hr = int(now.strftime(\"%H\"))   # Current Hour\n",
    "    min = int( now.strftime(\"%M\"))  # Current mint\n",
    "    \n",
    "    pywhatkit.sendwhatmsg(\"+919156566687\",\"Hi Pratik , Someone tried to access your app\", hr,min+1 ,wait_time=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wpmsg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access():\n",
    "    if FaceDetect == 50:\n",
    "        unlock = cv2.imread(\"unlock.jpg\")\n",
    "        \n",
    "        cv2.putText(unlock, \"Access\", (45, 50) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(unlock, \"Granted\", (45, 100) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow(\"lock\" , unlock)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Launching aws infrastructure with terraform\")\n",
    "        print(\"Installing required plugins\")\n",
    "        stream = os.popen('terraform init')\n",
    "        output = stream.readlines()\n",
    "        #output\n",
    "        for line in output:\n",
    "            print(line.strip())\n",
    "            \n",
    "        print(\"Deploying infrastructure\")\n",
    "        stream = os.popen('terraform apply')\n",
    "        output = stream.readlines()\n",
    "        #output\n",
    "        for line in output:\n",
    "            print(line.strip())\n",
    "        \n",
    "            \n",
    "            \n",
    "        print(\"Infra deployed\")\n",
    "        \n",
    "        \n",
    "    elif Anon == 120:\n",
    "        lock = cv2.imread(\"lock.jpg\")\n",
    "        cv2.putText(lock, \"Access\", (45, 50) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(lock, \"Denied\", (45, 100) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow(\"lock\" , lock)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        cv2.imshow(\"lock\" , image)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        cimg1 = image[y:y+h, x:x+w,  : ]\n",
    "        cv2.imwrite(\"./image/Crop.jpg\",cimg1)  \n",
    "        print(\"We are sending mail\")\n",
    "        send_email()\n",
    "        print(\"EMail sent sucessfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Face Detection+mail+whatsapp+terraform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-64-2fc338839950>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anon user\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-2fc338839950>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0maccess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-e890c157278a>\u001b[0m in \u001b[0;36maccess\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mcimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;33m:\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./image/Crop.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcimg1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"We are sending mail\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "FaceDetect = 0\n",
    "Anon = 0\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    cv2.imwrite(\"Mypic.jpg\" , image )\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        results = vimal_model.predict(face)\n",
    "\n",
    "        if results[1] < 500:\n",
    "            confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            display_string = str(confidence) + '% Confident it is User'\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence >= 90:\n",
    "            cv2.putText(image, \"Hii Pratik\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            FaceDetect += 1\n",
    "            \n",
    "        #elif confidence < 90:\n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, who are you\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            Anon += 1\n",
    "            \n",
    "        if FaceDetect == 50:\n",
    "            print(\"Your AWS infrastructure will be deployed\") \n",
    "            break\n",
    "            \n",
    "        elif Anon == 120:\n",
    "            print(\"Anon user\")            \n",
    "            break\n",
    "            \n",
    "            #print(\"We are sending mail\")\n",
    "            #send_email()\n",
    "            #print(\"EMail sent sucessfully\")\n",
    "            \n",
    "            \n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "access()\n",
    "cap.release()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0m\u001b[1mInitializing the backend...\u001b[0m\n",
      "\n",
      "\u001b[0m\u001b[1mInitializing provider plugins...\u001b[0m\n",
      "- Reusing previous version of hashicorp/aws from the dependency lock file\n",
      "- Using previously-installed hashicorp/aws v3.45.0\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[32mTerraform has been successfully initialized!\u001b[0m\u001b[32m\u001b[0m\n",
      "\u001b[0m\u001b[32m\n",
      "You may now begin working with Terraform. Try running \"terraform plan\" to see\n",
      "any changes that are required for your infrastructure. All Terraform commands\n",
      "should now work.\n",
      "\n",
      "If you ever set or change modules or backend configuration for Terraform,\n",
      "rerun this command to reinitialize your working directory. If you forget, other\n",
      "commands will detect it and remind you to do so if necessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "stream = os.popen('terraform init')\n",
    "output = stream.readlines()\n",
    "#output\n",
    "for line in output:\n",
    "   print(line.strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[1maws_instance.ec2_os: Refreshing state... [id=i-0c045b56bf4a5eca7]\u001b[0m\n",
      "\u001b[0m\u001b[1maws_ebs_volume.ebs_vol: Refreshing state... [id=vol-075e9f07f2f16d177]\u001b[0m\n",
      "\u001b[0m\u001b[1maws_volume_attachment.ebs_attach: Refreshing state... [id=vai-4124519776]\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[32m\n",
      "Apply complete! Resources: 0 added, 0 changed, 0 destroyed.\n",
      "\u001b[0m\u001b[0m\u001b[1m\u001b[32m\n",
      "Outputs:\n",
      "\n",
      "\u001b[0mImage_IP = \"52.66.251.98\"\n",
      "volume_Id = \"vol-075e9f07f2f16d177\"\n"
     ]
    }
   ],
   "source": [
    "stream = os.popen('terraform apply -auto-approve')\n",
    "output = stream.readlines()\n",
    "#output\n",
    "for line in output:\n",
    "   print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FaceDetect = 5\n",
    "Anon = 120\n",
    "import os\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access():\n",
    "    if FaceDetect == 50:\n",
    "        unlock = cv2.imread(\"unlock.jpg\")\n",
    "        \n",
    "        cv2.putText(unlock, \"Access\", (45, 50) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(unlock, \"Granted\", (45, 100) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow(\"lock\" , unlock)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Launching aws infrastructure with terraform\")\n",
    "        os.system(\"terraform init\")\n",
    "        os.system(\"terraform apply\")\n",
    "        print(\"Infra deployed\")\n",
    "        \n",
    "        \n",
    "    elif Anon == 120:\n",
    "        lock = cv2.imread(\"lock.jpg\")\n",
    "        cv2.putText(lock, \"Access\", (45, 50) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(lock, \"Denied\", (45, 100) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow(\"lock\" , lock)\n",
    "        cv2.waitKey(2000)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        cimg1 = image[ y:y+h ,x:x+w ,  : ]\n",
    "        cv2.imwrite(\"./image/Crop.jpg\",cimg1)  \n",
    "        print(\"We are sending mail\")\n",
    "        send_email()\n",
    "        print(\"EMail sent sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        ...,\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253]],\n",
       "\n",
       "       [[253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        ...,\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253]],\n",
       "\n",
       "       [[253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        ...,\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 249, 255],\n",
       "        [255, 249, 255],\n",
       "        [255, 249, 255],\n",
       "        ...,\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253]],\n",
       "\n",
       "       [[255, 247, 255],\n",
       "        [255, 248, 255],\n",
       "        [255, 248, 255],\n",
       "        ...,\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253]],\n",
       "\n",
       "       [[255, 247, 255],\n",
       "        [255, 247, 255],\n",
       "        [255, 247, 255],\n",
       "        ...,\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253],\n",
       "        [253, 253, 253]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.putText(lock, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
